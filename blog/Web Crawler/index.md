---
layout: post
title:  "😈 웹 크롤러 '회피 기동'"
subtitle: ""
type: "Development"
blog: true
text: true
comments: true
author: ""
post-header: true
header-img: "img/github.jpg"
order: 8
---

# 🤔 회피 기동이란?
뭐긴 뭐야 회피기동이란 내가 그냥 방금 만들어낸 이름이다. 크롤러가 어떤 웹 페이지를 지속적으로 긁을 때 해당 사이트로 부터 IP 차단을 당했을 경우 크롤러의 IP를 변경해서 우회하여 다시 해당 사이트를 긁는 기법을 나는 '회피 기동'이라고 멋진 이름을 갖다 붙였다. 이번 글에서는 어떻게 이 기능을 구현했었는지 메모 해 두려고 한다. 

# 💡 아이디어
처음 생각  해 놓은 아이디어는 크게 두 가지이다. 두개의 NIC의 장착한 서버를 임대하거나 Google Cloud나 AWS로부터 여러개의 IP를 할당 받아 번갈아 가며 사용 하는 것이다. 그러나 이 방법은 대충 생각 해 봐도 "할당 받은 IP 전부 차단 당하면 어쩔건데?"라는 물음에서 답을 찾기가 쉽지 않다. 또 여러개의 IP를 임대 할 수록 비용도 늘어 날 것이다. 이 글에서는 내 나름대로 효과를 본 방법 두가지를 메모 해 두려 한다.

사실 웹 크롤러를 만들어 본 사람들이라면 target 웹 페이지를 수분에 한 번 정도 긁는 정도라서 IP Block까지 가는 경우는 잘 없으리라 생각 된다. 그러나 나 같은 경우 target site를 실시간에 가깝게 content 변경을 감지 해야 했기 때문에 IP 회피 기동을 생각 해 내야만 했다. 

실시간 스캔을 한답시고 무작정 1초에 1번, 3초에 1번 등으로 알고리즘을 선택 했다간 차단이 아니라 고소장이 날아 올 것은 불 보듯 뻔 한 일이기에 간단하게 '다음에 방문할 시간'을 HTML 내용 변경 정도에 따라 결정하도록 간단한 수식을 작성 하였다. 코드로 쓰면 대충 아래와 같을 것이다.

```go
// [Deafult]
// url.visitInterval = time.Second * 60


if time.Since(url.previousVisitedTime) <= url.visitInterval {
	url.lastVisitedTime = time.Now()
	diff = ContentDiff(lastHTML, currentHTML)
    url.visitInterval = time.Second * 10 + (time.Second * diff * -1)
}
```

대충 기억나는대로 썼기 때문에 맞는 코드가 아닐 수도 있다. 그렇게 신경 쓰지 말자. 요점은 HTML content에 변경 사항이 없거나 적으면 nextVisit의 값은 거의 그 상태로 유지 될 것이라는 것이다. default 값이 60초 였고 해당 페이지가 별 변화가 없는 페이지라면 방문 간격은 거의 항상 60초를 왔다 갔다 할 것이고 어느 순간 페이지에 변화가 계속 생긴다면 50, 40, 30으로 줄어들면서 방문 간격이 줄어 들 것이다.

결국 100개의 target page가 있다고 가정 하면 이 중 '실제로 변화가 잦은 페이지'만 interval 간격이 0에 수렴하게 되고 변화가 없는 녀석들은 itnerval이 점점 증가하게 되는 간단한 알고리즘이다.



## 👨‍👩‍👧‍👧 대륙 분산
첫 번째 아이디어는 각 대륙별로 크롤러들을 분산 시키는 것이었다. AWS나 GCP를 사용한다면 이것은 그렇게 어려운 방법은 아니다. 기본적인 아이디어를 설명하자면 아래와 같다.


1. 서울, 도쿄, 홍콩에 크롤러들을 분산 시켜 둔다.
2. '도쿄'의 크롤러가 target에 request를 보내며 크롤을 시작한다.
3. '도쿄'가 IP block 됐을 경우 실패한 URL을 '서울' 크롤러에게 Fetch해 준다.
4. 도쿄가 실패한 URL은 이후로 IP block이 풀릴 때 까지 서울 크롤러가 담당한다.

![](https://images.velog.io/images/mowinckel/post/d3d03dc4-bb5c-4d93-960e-532475c64b82/AGS_RPO_APAC_Map%20jpg.jpg)

각 대륙별로 크롤러들을 분산하면 완전히 다른 IP 대역을 갖게 되고 이는 IP black list를 회피하기 용이 해 진다.  


### 분산 웹 크롤링
다만 위의 아이디어는 각 리전에 위치한 크롤러 세 대가 모두 협업을 잘 한다는 가정하게 가능한 이야기다. Distributed 되었다는 것은 아주 매력적이고 더 고난도의 기술이지만 세 대의 크롤러가 방문하는 URL들이 서로 잘 공유가 되어야 하고 '동기화' 해야만 한다. 대륙 별로 분산 되었다는 것은 latency가 필연적으로 클 수 밖에 없다는 것이고 이를 해결할 멋진 알고리즘이 필요하다. 크롤러들이 분산 협업을 하기로 결정한 순간, 사이트로 부터 block 당하는 경우가 아니라 크롤러끼리의 통신이 끊어지는 경우도 잘 생각해야만 했다.

게다가 URL Fetcher가 뒤져버리면 어떻게 하지? Single Point of Failure를 방지하기 위해서 Zookeeper가 동원되고 이 쯤 되면 대략 정신이 멍 해 지면서 내가 일개 웹 페이지 크롤링 좀 하겠답시고 이렇게까지 해야하나 하는 생각이 든다.


### Single Crawler
뭐든지 '분산'하는 것은 쉬운 일은 아니다. 때문에 최초에는 대륙 분산만을 해두고 크롤러 세 대 중 한대만을 가동했다. 만약 Failed URL이 발생하면 그제서야 다른 '서울'이나 '홍콩'의 크롤러들이 깨어나서 해당 URL만 긁고 다시 잠들어 버리도록 하였다. 


이 아이디어는 대륙 별로 협업을 하는 듯한 분위기로 아주 멋진 것 처럼 보이지만 실제로는 그다지 효율적이지 않다. 세 대의 서버 비용을 감당 해야하고 분산 된 크롤러들을 잘 동기화 할 수 있어야하며 이 때 Master / Slave 구조로서 URL Fetcher 서버가 따로 필요 할 수도 있다. 크롤러들이 P2P 구조로 각자가 하나의 독립된 크롤러라면 중복 방문을 어떻게 잘 관리 할지가 고민이다.

 
- 해외 아이피를 차단하는 경우 서울 리전의 크롤러 외엔 모두 Block되어 버릴 수 있다.
- 단순히 크롤러 3대의 IP를 모두 차단하면 무용지물이 된다.
- 서버 비용이 3배다. 필요 할 때만 Wake하고 다시 Sleep하게 한다면 비용이 줄겠지만 Wake 시간 때문에 '실시간' 크롤링과는 거리가 멀어진다.
- 분산 크롤링의 모델이 무엇이든간에 크롤러 서버 3대 외에 관리 해야할 서버가 더 늘어 날 수 있다. k8s와 같이 docker로 구성하는 방법을 생각 해 볼 필요가 있다.

## 😎 프록시 서버, Request 분산
단 하나의 머신만으로도 1초에 5번 10번씩 request를 날려도 block 당하지 않고 지속적으로 page를 크롤 할 수 있는 방법은 없을까? 이번 아이디어는 프록시 서버를 여러개 구성하고 크롤러의 Request를 Load Balancing하는 방법이다. 

L5/L7 Load Balancer는 클라이언트의 Request를 잘 분산해서 WAS에 전달하지만 이 경우는 그 반대라고 할 수 있다. 크롤러의 요청을 잘 분산해서 target domain에 전달 하는 것이다. 

앞서 말한 대륙 분산은 실제로 크롤러들을 물리적으로 해당 리전에 배치하는 것이지만 프록시 서버를 활용하면 굳이 크롤러를 '그 지역'에 배치하지 않고서도 '그 지역'인 척 흉내를 낼 수가 있다. AWS나 GCP는 모두 '서울'리전만 제공하는 것에 비해 프록시 서버는 국내의 더 정확한 위치인 대전, 대구, 광주, 부산등의 위치로 더 정교하게 구성 할 수 있어 IP block에 더 잘 대항 할 수 있게 된다. 마찬가지로 해외의 위치도 도쿄, 오사카, 지바 등으로 더 구체적으로 구성 할 수 있게 된다.


처음에는 전국에 오픈 되어 있는 SOCK4/5 또는 HTTP/S 프록시 서버를 list로 구축하고 Round Robin으로 Request를 날렸다. **쉽게 말해서 전국 팔도 사나이들이 몽둥이 들고 서울역에서 만나서 다같이 누굴 두들겨 패는 것이다.** 생각 해 봐라, 경상도 깡패랑 전라도 깡패가 상경해서 도시 깡패를 두들겨 패는 것이다. 가슴이 웅장해진다.

![](https://images.velog.io/images/mowinckel/post/2da00ed2-d9e8-449b-804e-79ea5b547ed8/Map_of_South_Korea-blank.svg)

### 싱글 머신
이렇게 프록시 서버를 리스트로 갖고 Http 요청을 경유하게 하면 단 한 대의 머신으로 분산 크롤링을 흉내 내면서 IP 역시 회피 기동 할 수 있다. 


> 물론 위에서 소개한 이 모든 짓거리는 DDOS 공격의 lite (순한 맛) 버전이나 다를 바 없는 것이다. 이 아이디어들은 target site가 조금만 스마트하게 운영되고 있다면 씨알도 안 먹히는 방법들이다. 간단하게 CloudFlare 서비스만 사용한다면 대부분의 크롤링은 힘도 못 쓸것이다.

(작성중)






